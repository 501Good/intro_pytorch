{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34gO2kLz8UWF"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "ccKYp3sQ8Y8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Load the FasionMNIST dataset from Hugging Face Hub."
      ],
      "metadata": {
        "id": "055XBP6UcJeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"fashion_mnist\")"
      ],
      "metadata": {
        "id": "3KyNzvN28av5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See what's inside of the dataset"
      ],
      "metadata": {
        "id": "LLLuDLILcOPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "m1WrnJRm8y4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images in the dataset are in the PIL format originally."
      ],
      "metadata": {
        "id": "iDe6nPh9clsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']['image'][0]"
      ],
      "metadata": {
        "id": "db53Vrin806o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract all the label names."
      ],
      "metadata": {
        "id": "c6EF8mYjcqyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset['train'].features['label'].names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "0iFKKwUGCUDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize more examples."
      ],
      "metadata": {
        "id": "BMwJanS_cuVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(dataset['train']), size=[1]).item()\n",
        "    img, label = dataset['train']['image'][random_idx], dataset['train']['label'][random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "GRcIjLJbCNXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert from the PIL format to the Pytorch tensors for our model."
      ],
      "metadata": {
        "id": "gV75fjH1cyh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = ToTensor()"
      ],
      "metadata": {
        "id": "Csk3anV483dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform(dataset['train']['image'][0])"
      ],
      "metadata": {
        "id": "tHQig7es9TqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the dimensions of our image. It should be 28x28."
      ],
      "metadata": {
        "id": "hzpttk8hc6fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform(dataset['train']['image'][0]).shape"
      ],
      "metadata": {
        "id": "5iLG3vYbc5db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the transformation to all the images in the dataset."
      ],
      "metadata": {
        "id": "maeEU_D3dCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_pil_to_tensor(sample):\n",
        "    sample['image'] = [transform(image) for image in sample['image']]\n",
        "    sample['label'] = torch.tensor(sample['label'])\n",
        "    return sample\n",
        "\n",
        "train_dataset = dataset['train'].with_transform(map_pil_to_tensor)\n",
        "test_dataset = dataset['test'].with_transform(map_pil_to_tensor)"
      ],
      "metadata": {
        "id": "_HLHnKwT9Wsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Dataloader to iterate the dataset with the mini-batches."
      ],
      "metadata": {
        "id": "n2Hz-h6fdGwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "eaHps1Pb93dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_batch = next(iter(train_dataloader))\n",
        "train_batch['image'], train_batch['label']"
      ],
      "metadata": {
        "id": "vTtky6RAAS1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "Create the `device` variable for the device-agnostic code."
      ],
      "metadata": {
        "id": "OYxTS_PLdPLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "VRtt4YVUEKFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the TinyVGG architecture that looks like this:\n",
        "\n",
        "```\n",
        "TinyVGG(\n",
        "  (block_1): Sequential(\n",
        "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (1): ReLU()\n",
        "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (3): ReLU()\n",
        "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  )\n",
        "  (block_2): Sequential(\n",
        "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (1): ReLU()\n",
        "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (3): ReLU()\n",
        "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  )\n",
        "  (classifier): Sequential(\n",
        "    (0): Flatten(start_dim=1, end_dim=-1)\n",
        "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
        "  )\n",
        ")\n",
        "```\n",
        "\n",
        "You will need the following layers:\n",
        "\n",
        "- [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d)\n",
        "- [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d)\n",
        "- [`nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu)\n",
        "- [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#flatten)\n",
        "- [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear)\n",
        "- [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#sequential)"
      ],
      "metadata": {
        "id": "UaXE-KQ0dksI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        ...\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = TinyVGG(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "U5V6j8DhEP78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3jlKzO9Ietkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(),\n",
        "                             lr=0.1)"
      ],
      "metadata": {
        "id": "KQ5qwsZoHG7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "56u2aJIIIBLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the training step and test step.\n",
        "\n",
        "Remember, for training step:\n",
        "\n",
        "1. Set the model to the training mode (`model.train()`)\n",
        "2. Take a data mini-batch (transfer the data to the `device`)\n",
        "3. Forward pass of the model\n",
        "4. Calculate loss (and other metrics)\n",
        "5. Zero the gradients\n",
        "6. Perform backward pass (`loss.backward()`)\n",
        "7. Do the optimizer step\n",
        "8. Print out the information if necessary\n",
        "\n",
        "For test step:\n",
        "\n",
        "1. Set the model to the evaluation mode (`model.eval()`) and switch off the gradients (`with torch.no_grad()`)\n",
        "2. Take a data mini-batch (transfer the data to the `device`)\n",
        "3. Forward pass of the model\n",
        "4. Calculate loss (and other metrics)\n",
        "5. Print out the information if necessary"
      ],
      "metadata": {
        "id": "6rjdn7oxepcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for batch, batch_data in enumerate(data_loader):\n",
        "        # Send data to GPU\n",
        "        ...\n",
        "\n",
        "        # 1. Forward pass\n",
        "        ...\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = ...\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        ...\n",
        "\n",
        "        # 4. Loss backward\n",
        "        ...\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        ...\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for batch_data in data_loader:\n",
        "            # Send data to GPU\n",
        "            ...\n",
        "\n",
        "            # 1. Forward pass\n",
        "            ...\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "mWGGOqxBHaYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to train the model and look at the metrics (for extra, you can try to add the Tensorboard logging here)"
      ],
      "metadata": {
        "id": "iFKv4oDTf36q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model = timer()\n",
        "\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time\n",
        "\n",
        "# Train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "train_time_end_model = timer()\n",
        "total_train_time_model = print_train_time(start=train_time_start_model,\n",
        "                                           end=train_time_end_model,\n",
        "                                           device=device)"
      ],
      "metadata": {
        "id": "d9rQpsTeH2PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model\n",
        "\n",
        "Implement the model saving here"
      ],
      "metadata": {
        "id": "49WxaSVpgBO9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vaxFdUCYIrLI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}